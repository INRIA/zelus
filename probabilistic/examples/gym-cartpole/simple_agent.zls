open Cart_pole
open Pendulum

let node cart_pole_zls (obs0, action) = obs, reward, stop where
  rec automaton
      | Reset ->
          do obs, reward, stop = simple_pendulum (obs0, action)
          until stop then Reset

(** Probabilistic model training one neuron **)

type net = { k1: float; k2: float; k3: float; k4: float}
let node controller (net, obs) = action where
  rec force = net.k1 *. obs.cart_position
      +. net.k2 *. obs.cart_velocity
      +. net.k3 *. obs.pole_angle
      +. net.k4 *. obs.pole_velocity
  and  action = if force > 0. then Right else Left


let node model (score, obs_gym) = score', net where
  rec init net = {
    k1 = Infer.sample(Distribution.gaussian 0. 1.);
    k2 = Infer.sample(Distribution.gaussian 0. 1.);
    k3 = Infer.sample(Distribution.gaussian 0. 1.);
    k4 = Infer.sample(Distribution.gaussian 0. 1.);
  }
  and obs, reward, stop = cart_pole_zls (obs_gym, (Right fby action))
  and action = controller (net, obs)
  and score' = Infer.factor(score, 10. *. reward)


(** Connect with the physical model of the openai gym **)

let node cart_pole_gym render action = obs, reward, stop where
  rec init instance_id = cart_init ()
  and init r = 0.
  and automaton
      | Reset -> local dummy
          do obs, reward, stop = cart_reset instance_id, 1., false
          and dummy = print_endline ("Episode reward: "^(string_of_float (last r)))
          and r = 0.
          then Run
      | Run ->
          do obs, reward, stop = cart_step instance_id action render
          and r = reward +. last r
          until stop then Reset

(** Infer the neuron using the Zelus model and simulate with the openai gym**)

let node main () = () where
  rec net_dist = Infer.infer 1000 model (true, obs)
  and net = Distribution.draw net_dist
  and obs, _, _ = cart_pole_gym true (Right fby action)
  and action = controller (net, obs)
